{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 1\n",
    "#### http://neuralnetworksanddeeplearning.com/chap1.html#exercise_263792\n",
    "##### done by: github.com/famu8 | Fernando Augusto Marina Urriola\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question\n",
    "An extreme version of gradient descent is to use a mini-batch size of just 1. That is, given a training input, x\n",
    ", we update our weights and biases according to the rules wk→w′k=wk−η∂Cx/∂wk\n",
    " and bl→b′l=bl−η∂Cx/∂bl\n",
    ". Then we choose another training input, and update the weights and biases again. And so on, repeatedly. This procedure is known as online, on-line, or incremental learning. In online learning, a neural network learns from just one training input at a time (just as human beings do). Name one advantage and one disadvantage of online learning, compared to stochastic gradient descent with a mini-batch size of, say, 20\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Solution\n",
    "Advantage of online learning compared to stochastic gradient descent with a mini-batch size of 20:\n",
    "\n",
    "**Fast Adaptation to Changing Data**: Online learning allows a neural network to quickly adapt to changing data patterns. Since it updates the weights and biases after processing each individual training input, it can respond rapidly to new information or evolving trends in the data. This makes it well-suited for scenarios where the data distribution is non-stationary or where new data is continuously arriving.\n",
    "\n",
    "Disadvantage of online learning compared to stochastic gradient descent with a mini-batch size of 20:\n",
    "\n",
    "**High Variance in Updates**: Online learning can suffer from high variance in weight updates since it updates the model's parameters based on single data points. This variance can lead to erratic training behavior, making convergence slower and potentially causing the model to get stuck in local minima. In contrast, stochastic gradient descent with a mini-batch size of 20 or more provides smoother updates, which can help in reaching a more stable and better-performing solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily based on https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "\n",
    "> **NOTE** In the last part of this lab cuda is used. If you have a cuda enabled machine, read the README.md in the root of this repo on how to use nvidia-docker.\n",
    "\n",
    "\n",
    "It’s a Python based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "-  A replacement for numpy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility\n",
    "   and speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this lab you will get a quick start on what pytorch is and how to use it.\n",
    "\n",
    "## 1. Tensors\n",
    "\n",
    "Tensors are similar to numpy’s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 5x3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4443e-30, 7.9454e-43, 1.4443e-30],\n",
      "        [7.9454e-43, 1.4443e-30, 7.9454e-43],\n",
      "        [1.4443e-30, 7.9454e-43, 1.4443e-30],\n",
      "        [7.9454e-43, 1.4443e-30, 7.9454e-43],\n",
      "        [1.4443e-30, 7.9454e-43, 1.4443e-30]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "#random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3660, 0.0452, 0.7618],\n",
      "        [0.4303, 0.0403, 0.5963],\n",
      "        [0.3653, 0.3640, 0.3383],\n",
      "        [0.4470, 0.6776, 0.2404],\n",
      "        [0.8408, 0.0532, 0.4989]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "#random numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: `torch.Size` is in fact a tuple, so it supports the same operations that a tuple supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3660, 0.0452, 0.7618],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.4470, 0.6776, 0.2404],\n",
      "        [0.8408, 0.0532, 0.4989]])\n"
     ]
    }
   ],
   "source": [
    "x[1:3] = 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Make use of the pytorch docs <http://pytorch.org/docs/torch>\n",
    "1. Make a tensor of size (2, 17)\n",
    "2. Make a torch.FloatTensor of size (3, 1)\n",
    "3. Make a torch.LongTensor of size (5, 2, 1)\n",
    "  - fill the entire tensor with 7s\n",
    "4. Make a torch.ByteTensor of size (5,)\n",
    "  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0561e-38, 1.0653e-38, 4.1327e-39, 8.9082e-39, 9.8265e-39, 9.4592e-39,\n",
      "         1.0561e-38, 1.0653e-38, 1.0469e-38, 9.5510e-39, 1.0102e-38, 8.4490e-39,\n",
      "         1.0102e-38, 1.0469e-38, 1.0102e-38, 9.6429e-39, 8.4490e-39],\n",
      "        [1.0745e-38, 1.0102e-38, 9.6429e-39, 9.2756e-39, 8.4490e-39, 1.1112e-38,\n",
      "         8.9082e-39, 9.6429e-39, 8.4490e-39, 1.0194e-38, 1.0745e-38, 9.2755e-39,\n",
      "         8.4490e-39, 9.6429e-39, 9.2755e-39, 1.0469e-38, 1.0469e-38]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(2,17)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "b= torch.FloatTensor(3,1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "c = torch.LongTensor(5,2,1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.full((5,2,1),7,dtype=torch.int64)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "d = torch.ByteTensor(5,)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "d[1:4]=1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Operations\n",
    "There are multiple syntaxes for operations. Let's see addition as an example:\n",
    "\n",
    "### 2.1 Addition: syntax 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6506, 0.2786, 1.4628],\n",
      "        [2.9307, 2.9672, 2.1787],\n",
      "        [2.2699, 2.7400, 2.5253],\n",
      "        [0.7027, 1.0780, 0.8871],\n",
      "        [1.1721, 0.3413, 0.5439]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Addition: syntax 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6506, 0.2786, 1.4628],\n",
      "        [2.9307, 2.9672, 2.1787],\n",
      "        [2.2699, 2.7400, 2.5253],\n",
      "        [0.7027, 1.0780, 0.8871],\n",
      "        [1.1721, 0.3413, 0.5439]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Addition: giving an output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6506, 0.2786, 1.4628],\n",
      "        [2.9307, 2.9672, 2.1787],\n",
      "        [2.2699, 2.7400, 2.5253],\n",
      "        [0.7027, 1.0780, 0.8871],\n",
      "        [1.1721, 0.3413, 0.5439]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Addition: in-place\n",
    "\n",
    "adds `x`to `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6506, 0.2786, 1.4628],\n",
      "        [2.9307, 2.9672, 2.1787],\n",
      "        [2.2699, 2.7400, 2.5253],\n",
      "        [0.7027, 1.0780, 0.8871],\n",
      "        [1.1721, 0.3413, 0.5439]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Any operation that mutates a tensor in-place is post-fixed with an `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard numpy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 0.6776, 0.0532])\n"
     ]
    }
   ],
   "source": [
    "print(x[2:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3660, 0.0452, 0.7618],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.4470, 0.6776, 0.2404],\n",
      "        [0.8408, 0.0532, 0.4989]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later** 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described here <http://pytorch.org/docs/torch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. multiplication of two tensors (see [torch.Tensor.mul](http://pytorch.org/docs/master/tensors.html#torch.Tensor.mul))\n",
    "2. do the same, but inplace\n",
    "3. division of two tensors (see [torch.Tensor.div](http://pytorch.org/docs/master/tensors.html#torch.Tensor.div))\n",
    "4. perform a matrix multiplication of two tensors of size (2, 4) and (4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3807],\n",
      "        [0.0601],\n",
      "        [0.0625],\n",
      "        [0.0516],\n",
      "        [0.1597]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.rand(5,1)\n",
    "f = torch.rand(5,1)\n",
    "# h = torch.Tensor(5,1) ---> valid. they act as matrices\n",
    "g = torch.Tensor.mul(e,f)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3807],\n",
      "        [0.0601],\n",
      "        [0.0625],\n",
      "        [0.0516],\n",
      "        [0.1597]])\n"
     ]
    }
   ],
   "source": [
    "e.mul_(f)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4351],\n",
      "        [0.2301],\n",
      "        [0.0819],\n",
      "        [0.3761],\n",
      "        [0.4125]])\n"
     ]
    }
   ],
   "source": [
    "h = torch.Tensor.div(e,f)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([2, 4])\n",
      "tensor([[0.4325, 0.0910, 0.4308, 0.3143],\n",
      "        [0.9888, 0.2242, 0.9787, 0.7407],\n",
      "        [0.1463, 0.0080, 0.1544, 0.0752],\n",
      "        [0.1599, 0.0255, 0.1624, 0.1051]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(4,2)\n",
    "print(x1.shape)\n",
    "x2 = torch.rand(2,4)\n",
    "print(x2.shape)\n",
    "print(torch.mm(x1,x2))\n",
    "#mm = matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numpy Bridge\n",
    "\n",
    "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
    "\n",
    "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "### 3.1 Converting torch Tensor to numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value: the `numpy()` method provides a *view* of the original tensor, not a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Converting numpy Array to torch Tensor\n",
    "\n",
    "See how changing the np array changed the torch Tensor automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "#creates a tensor from a np.array\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. create a tensor of size (5, 2) containing ones\n",
    "2. now convert it to a numpy array\n",
    "3. now convert it back to a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.ones(5,2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = x3.numpy()\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x5 = torch.from_numpy(x4)\n",
    "print(x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
    "\n",
    "## 4 CUDA Tensors\n",
    "\n",
    "Tensors can be moved onto GPU using the `.cuda` function.\n",
    "This is not necessary, but check the `README.md` for details on how to use a GPU with docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3660, 0.0452, 0.7618],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.4470, 0.6776, 0.2404],\n",
      "        [0.8408, 0.0532, 0.4989]], device='cuda:0')\n",
      "tensor([[0.6506, 0.2786, 1.4628],\n",
      "        [2.9307, 2.9672, 2.1787],\n",
      "        [2.2699, 2.7400, 2.5253],\n",
      "        [0.7027, 1.0780, 0.8871],\n",
      "        [1.1721, 0.3413, 0.5439]], device='cuda:0')\n",
      "tensor([[1.0167, 0.3238, 2.2246],\n",
      "        [4.9307, 4.9672, 4.1787],\n",
      "        [4.2699, 4.7400, 4.5253],\n",
      "        [1.1497, 1.7556, 1.1274],\n",
      "        [2.0129, 0.3945, 1.0427]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = x + y\n",
    "    # Notice that the tensors are now of type torch.cuda.FloatTensor (notice the cuda in there)\n",
    "    # This is meant as a tensor to be run on the GPU.\n",
    "    # The .cuda() does this to any parameter it is applied to.\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "else:\n",
    "    print(\"CUDA not available on your machine.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
